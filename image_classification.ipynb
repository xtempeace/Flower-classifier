{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b796a804",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: torch in c:\\users\\singh\\appdata\\roaming\\python\\python311\\site-packages (2.4.1)\n",
      "Requirement already satisfied: filelock in c:\\programdata\\anaconda3\\lib\\site-packages (from torch) (3.9.0)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in c:\\users\\singh\\appdata\\roaming\\python\\python311\\site-packages (from torch) (4.12.2)\n",
      "Requirement already satisfied: sympy in c:\\programdata\\anaconda3\\lib\\site-packages (from torch) (1.11.1)\n",
      "Requirement already satisfied: networkx in c:\\programdata\\anaconda3\\lib\\site-packages (from torch) (3.1)\n",
      "Requirement already satisfied: jinja2 in c:\\programdata\\anaconda3\\lib\\site-packages (from torch) (3.1.2)\n",
      "Requirement already satisfied: fsspec in c:\\programdata\\anaconda3\\lib\\site-packages (from torch) (2023.4.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from jinja2->torch) (2.1.1)\n",
      "Requirement already satisfied: mpmath>=0.19 in c:\\programdata\\anaconda3\\lib\\site-packages (from sympy->torch) (1.3.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "feb90f23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: torchvision in c:\\users\\singh\\appdata\\roaming\\python\\python311\\site-packages (0.19.1)\n",
      "Requirement already satisfied: numpy in c:\\programdata\\anaconda3\\lib\\site-packages (from torchvision) (1.24.3)\n",
      "Requirement already satisfied: torch==2.4.1 in c:\\users\\singh\\appdata\\roaming\\python\\python311\\site-packages (from torchvision) (2.4.1)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from torchvision) (9.4.0)\n",
      "Requirement already satisfied: filelock in c:\\programdata\\anaconda3\\lib\\site-packages (from torch==2.4.1->torchvision) (3.9.0)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in c:\\users\\singh\\appdata\\roaming\\python\\python311\\site-packages (from torch==2.4.1->torchvision) (4.12.2)\n",
      "Requirement already satisfied: sympy in c:\\programdata\\anaconda3\\lib\\site-packages (from torch==2.4.1->torchvision) (1.11.1)\n",
      "Requirement already satisfied: networkx in c:\\programdata\\anaconda3\\lib\\site-packages (from torch==2.4.1->torchvision) (3.1)\n",
      "Requirement already satisfied: jinja2 in c:\\programdata\\anaconda3\\lib\\site-packages (from torch==2.4.1->torchvision) (3.1.2)\n",
      "Requirement already satisfied: fsspec in c:\\programdata\\anaconda3\\lib\\site-packages (from torch==2.4.1->torchvision) (2023.4.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from jinja2->torch==2.4.1->torchvision) (2.1.1)\n",
      "Requirement already satisfied: mpmath>=0.19 in c:\\programdata\\anaconda3\\lib\\site-packages (from sympy->torch==2.4.1->torchvision) (1.3.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2ad6dc0b-c30f-4300-9e62-dad86e69148f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms, models\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "982f34b8-1c35-4767-8c19-5ee446aab58e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define data transformations for data augmentation and normalization\n",
    "data_transforms = {\n",
    "    'train': transforms.Compose([\n",
    "        transforms.RandomResizedCrop(224),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "    'val': transforms.Compose([\n",
    "        transforms.Resize(256),\n",
    "        transforms.CenterCrop(224),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "5c86d400-80fe-41bf-bd98-c4d92f6036b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the data directory\n",
    "data_dir = 'datasetspiral'\n",
    "\n",
    "# Create data loaders\n",
    "image_datasets = {x: datasets.ImageFolder(os.path.join(data_dir, x), data_transforms[x]) for x in ['train', 'val']}\n",
    "#image_datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "678a888b-f751-4e87-be61-55a92be361c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'train': 72, 'val': 30}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['healthy', 'parkinson']"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataloaders = {x: torch.utils.data.DataLoader(image_datasets[x], batch_size=4, shuffle=True, num_workers=4) for x in ['train', 'val']}\n",
    "dataset_sizes = {x: len(image_datasets[x]) for x in ['train', 'val']}\n",
    "print(dataset_sizes)\n",
    "\n",
    "class_names = image_datasets['train'].classes\n",
    "class_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "d7f4d89f-c66d-473a-b526-d4cbb991339b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the pre-trained ResNet-18 model\n",
    "model = models.resnet18(pretrained=True)\n",
    "\n",
    "# Freeze all layers except the final classification layer\n",
    "for name, param in model.named_parameters():\n",
    "    if \"fc\" in name:  # Unfreeze the final classification layer\n",
    "        param.requires_grad = True\n",
    "    else:\n",
    "        param.requires_grad = False\n",
    "\n",
    "# Define the loss function and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)  # Use all parameters\n",
    "\n",
    "\n",
    "# Move the model to the GPU if available\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = model.to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "fe788bcb-77d7-4c86-9f4b-80868208b8ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 3.8891 Acc: 0.3611\n",
      "val Loss: 1.1010 Acc: 0.5667\n",
      "train Loss: 0.9508 Acc: 0.5833\n",
      "val Loss: 1.5462 Acc: 0.5667\n",
      "train Loss: 0.7319 Acc: 0.5972\n",
      "val Loss: 1.5885 Acc: 0.5333\n",
      "train Loss: 0.8651 Acc: 0.6389\n",
      "val Loss: 1.2679 Acc: 0.6333\n",
      "train Loss: 0.8629 Acc: 0.5556\n",
      "val Loss: 0.9223 Acc: 0.6333\n",
      "train Loss: 0.7987 Acc: 0.6944\n",
      "val Loss: 0.5491 Acc: 0.7000\n",
      "train Loss: 0.5693 Acc: 0.7083\n",
      "val Loss: 0.5505 Acc: 0.7667\n",
      "train Loss: 1.0355 Acc: 0.5972\n",
      "val Loss: 1.6552 Acc: 0.5667\n",
      "train Loss: 1.8075 Acc: 0.5000\n",
      "val Loss: 1.9465 Acc: 0.5667\n",
      "train Loss: 1.4257 Acc: 0.5556\n",
      "val Loss: 0.4661 Acc: 0.7333\n",
      "train Loss: 0.7152 Acc: 0.6944\n",
      "val Loss: 0.5416 Acc: 0.7667\n",
      "train Loss: 0.5452 Acc: 0.7222\n",
      "val Loss: 0.4598 Acc: 0.7667\n",
      "Training complete!\n"
     ]
    }
   ],
   "source": [
    "# Training loop\n",
    "num_epochs = 12\n",
    "for epoch in range(num_epochs):\n",
    "    for phase in ['train', 'val']:\n",
    "        if phase == 'train':\n",
    "            model.train()\n",
    "        else:\n",
    "            model.eval()\n",
    "\n",
    "        running_loss = 0.0\n",
    "        running_corrects = 0\n",
    "\n",
    "        for inputs, labels in dataloaders[phase]:\n",
    "            inputs = inputs.to(device) #image\n",
    "            labels = labels.to(device) #class name\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            with torch.set_grad_enabled(phase == 'train'):\n",
    "                outputs = model(inputs)\n",
    "                _, preds = torch.max(outputs, 1)\n",
    "                loss = criterion(outputs, labels)\n",
    "\n",
    "                if phase == 'train':\n",
    "                    loss.backward()\n",
    "                    optimizer.step()\n",
    "\n",
    "            running_loss += loss.item() * inputs.size(0)\n",
    "            running_corrects += torch.sum(preds == labels.data)\n",
    "\n",
    "        epoch_loss = running_loss / dataset_sizes[phase]\n",
    "        epoch_acc = running_corrects.double() / dataset_sizes[phase]\n",
    "\n",
    "        print(f'{phase} Loss: {epoch_loss:.4f} Acc: {epoch_acc:.4f}')\n",
    "\n",
    "print(\"Training complete!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "2c696019-b8ca-4cac-9f5f-d350e7285265",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Save the model\n",
    "torch.save(model.state_dict(), 'disease_classification_model.pth')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7057bb6d-9592-4809-af3a-fb05ef595477",
   "metadata": {},
   "source": [
    "# Classification on Unseen Image"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c98f514-6ad8-46cb-b9b6-f56f7da59476",
   "metadata": {},
   "source": [
    "To use the saved model to classify unseen images, you need to load the model and then apply it to the new images for inference. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "2a509530-539e-4e35-8a1b-181215da720b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Singh\\AppData\\Local\\Temp\\ipykernel_6480\\3424050668.py:8: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load('disease_classification_model.pth'))\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torchvision import models, transforms\n",
    "from PIL import Image\n",
    "\n",
    "# Load the saved model\n",
    "model = models.resnet18(pretrained=True)\n",
    "model.fc = nn.Linear(model.fc.in_features, 1000)  # Adjust to match the original model's output units\n",
    "model.load_state_dict(torch.load('disease_classification_model.pth'))\n",
    "model.eval()\n",
    "\n",
    "# Create a new model with the correct final layer\n",
    "new_model = models.resnet18(pretrained=True)\n",
    "new_model.fc = nn.Linear(new_model.fc.in_features, 2)  # Adjust to match the desired output units\n",
    "\n",
    "# Copy the weights and biases from the loaded model to the new model\n",
    "new_model.fc.weight.data = model.fc.weight.data[0:2]  # Copy only the first 2 output units\n",
    "new_model.fc.bias.data = model.fc.bias.data[0:2]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9557a6cc-c536-44b7-bfad-52f3d33e1480",
   "metadata": {},
   "source": [
    "Prepare your new image for classification. You should use the same data transformations you used during training. Here's an example of how to prepare an image for inference:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "1445dcf2-2311-4025-80e9-2b57ccf559e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and preprocess the unseen image\n",
    "image_path = 'test5.jpg'  # Replace with the path to your image\n",
    "image = Image.open(image_path)\n",
    "preprocess = transforms.Compose([\n",
    "    transforms.Resize(256),\n",
    "    transforms.CenterCrop(224),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "])\n",
    "input_tensor = preprocess(image)\n",
    "input_batch = input_tensor.unsqueeze(0)  # Add a batch dimension\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15505026-2f4d-4072-9ba1-c3dc265a43b1",
   "metadata": {},
   "source": [
    "Perform inference using the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "1aefe032-46f2-4f08-984e-39584a83cb21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The predicted class is: parkinson\n"
     ]
    }
   ],
   "source": [
    "# Perform inference\n",
    "with torch.no_grad():\n",
    "    output = model(input_batch)\n",
    "\n",
    "# Get the predicted class\n",
    "_, predicted_class = output.max(1)\n",
    "\n",
    "# Map the predicted class to the class name\n",
    "class_names = ['healthy', 'parkinson']  # Make sure these class names match your training data\n",
    "predicted_class_name = class_names[predicted_class.item()]\n",
    "\n",
    "print(f'The predicted class is: {predicted_class_name}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "657ea260-40c3-4a69-bb48-8de4fe305717",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "\n",
    "# Display the image with the predicted class name\n",
    "image = np.array(image)\n",
    "plt.imshow(image)\n",
    "plt.axis('off')\n",
    "plt.text(10, 10, f'Predicted: {predicted_class_name}', fontsize=12, color='white', backgroundcolor='red')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77cdda75-618a-4b16-884a-6b30d9a7d381",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
